{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recorded-spanish",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moving-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset_functions import *\n",
    "from common_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-coaching",
   "metadata": {},
   "source": [
    "# MULTIVARIABLE LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-diagram",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-turkey",
   "metadata": {},
   "source": [
    "### COST AND GRADIENT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "third-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coste(theta, X, Y, lam):\n",
    "    \"\"\"\n",
    "    Función de coste, recibe como entrada las thetas, las características,\n",
    "    los resultados y el parámetro lambda de regularización,\n",
    "    devuelve el coste regularizado\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "\n",
    "    h_theta = np.dot(X, theta)\n",
    "    sig = sigmoid(h_theta)\n",
    "    positive = np.dot(np.log(sig).T, Y)\n",
    "    negative = np.dot(np.log(1 - sig).T, 1 - Y)\n",
    "    J_theta = (-1 / m) * (positive + negative)\n",
    "    \n",
    "    # Regularizacion\n",
    "    reg = (lam /(2 * m)) * np.sum(np.square(theta))\n",
    "    \n",
    "    # Coste Regularizado\n",
    "    J_theta += reg\n",
    "    \n",
    "    return J_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incredible-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente(theta, X, Y, lam):\n",
    "    \"\"\"\n",
    "    Función de gradiente, recibe como entrada las thetas, las características,\n",
    "    los resultados y el parámetro lambda de regularización,\n",
    "    devuelve la gradiente regularizada\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    h_theta = np.dot(X, theta.T)\n",
    "    sig = sigmoid(h_theta)\n",
    "    gradient = (1/m) * np.dot(sig.T - Y, X)\n",
    "    \n",
    "    # Regularizacion\n",
    "    reg = (lam / m) * theta\n",
    "    \n",
    "    # Gradiente Regularizada\n",
    "    gradient += reg\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-programmer",
   "metadata": {},
   "source": [
    "### PLOT LAMBDAS / COST FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pressing-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cost_lambdas(lambdas_list, costs_list):\n",
    "    \"\"\"\n",
    "    Función que imprime las lambdas en el eje X,\n",
    "    y el coste en el eje Y\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(lambdas_list, costs_list, c = 'r')\n",
    "    plt.xlabel('lambda')\n",
    "    plt.ylabel('cost')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-rebecca",
   "metadata": {},
   "source": [
    "### PREDICTION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wrapped-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X, Y):\n",
    "    \"\"\"\n",
    "    Función que, a partir de las thetas, las características,\n",
    "    los resultados, calcula el porcentaje de acierto que tiene nuestra IA\n",
    "    Imprime el porcentaje con dos decimales\n",
    "    \"\"\"\n",
    "    predictions = np.dot(X, theta) > 0\n",
    "    \n",
    "    hits = np.sum(predictions == Y)\n",
    "    percentage = hits / X.shape[0] * 100\n",
    "    \n",
    "    print(\"The logistic regression is reliable in {:.2f}% of the time\\n\".format(percentage))\n",
    "    \n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-unknown",
   "metadata": {},
   "source": [
    "### CHOOSE OPTIMAL VALUES FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "middle-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt_thetas(theta, X, Y, reg = True):\n",
    "    \"\"\"\n",
    "    Función que recibe como entrada las thetas, las características,\n",
    "    los resultados y si se quiere aplicar un parámetro de regularización.\n",
    "    Devuelve la theta optima con diferentes regularizaciones (en el caso de\n",
    "    que reg = True)\n",
    "    Además, llama a la función 'print_cost_lambdas' para comparar los\n",
    "    distintos costes con las diferentes regularizaciones\n",
    "    \"\"\"\n",
    "    # Inicializamos los valores\n",
    "    lambdas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3]\n",
    "    n = X.shape[1]   \n",
    "    \n",
    "    theta_opt = np.zeros(n)\n",
    "    lambd_opt = lambdas[0]\n",
    "    cost_list = []\n",
    "    \n",
    "    \n",
    "    # Probamos los distintos parámetros de regularización\n",
    "    if reg:\n",
    "        for lambd in lambdas:\n",
    "\n",
    "            theta, _, _ = opt.fmin_tnc(\n",
    "                func=coste,\n",
    "                x0 = theta,\n",
    "                fprime=gradiente,\n",
    "                args=(X, Y, lambd)\n",
    "            )\n",
    "            \n",
    "            actual_cost = coste(theta, X, Y, lambd)\n",
    "            opt_cost = coste(theta_opt, X, Y, lambd_opt)\n",
    "\n",
    "\n",
    "            # Coste actual vs Coste óptimo\n",
    "            if (opt_cost > actual_cost):\n",
    "                theta_opt = theta\n",
    "                lambd_opt = lambd\n",
    "\n",
    "            cost_list.append(actual_cost)\n",
    "            \n",
    "        # Dibujamos la evolución del coste respecto a la regularización\n",
    "        print_cost_lambdas(lambdas, cost_list)\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        theta_opt, _, _ = opt.fmin_tnc(\n",
    "            func=coste,\n",
    "            x0 = theta,\n",
    "            fprime=gradiente,\n",
    "            args=(X, Y, 0)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    return theta_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-occurrence",
   "metadata": {},
   "source": [
    "## EXTERNAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baking-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lr_model(thetas):\n",
    "    \"\"\"\n",
    "    Guarda un array de thetas en la ruta models/theta_lr.npy\n",
    "    \"\"\"\n",
    "    np.save(\"models/theta_lr.npy\", thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "molecular-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lr_model():  \n",
    "    \"\"\"\n",
    "    Carga un array de thetas en la ruta models/theta_lr.npy\n",
    "    \"\"\"\n",
    "    thetas = np.load(\"models/theta_lr.npy\")\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modern-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lr_prediction():\n",
    "    \"\"\"\n",
    "    Carga los datos y las thetas óptimas, divide los datos y\n",
    "    prueba las thetas óptimas sobre esos datos.\n",
    "    Finalmente muestra el porcentaje de acierto de esos datos\n",
    "    \"\"\"\n",
    "    X, Y = read_dataset()\n",
    "    X, Y = manage_data(X, Y, use_onehot = False)\n",
    "    _, _, _, _, X_test, Y_test = divide_dataset(X, Y)\n",
    "    theta = load_lr_model()\n",
    "        \n",
    "    predict(theta, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interracial-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_example_lr(example):\n",
    "    \"\"\"\n",
    "    Carga las theta óptimas y, a partir de un ejemplo, predice su resultado\n",
    "    devuelve la predicción como booleano\n",
    "    \"\"\"\n",
    "    theta = load_lr_model()\n",
    "    prediction = np.dot(example, theta) > 0\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "professional-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_lr():\n",
    "    \"\"\"\n",
    "    Función que entrena el clasificador, obtiene las theta óptimas y\n",
    "    guarda el modelo óptimo.\n",
    "    \"\"\"\n",
    "    X, Y = read_dataset()\n",
    "    X, Y = manage_data(X, Y, use_onehot = False)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "\n",
    "    X_train, Y_train, _, _, X_test, Y_test = divide_dataset(X, Y)\n",
    "\n",
    "    theta = np.zeros(n)\n",
    "    \n",
    "    # CLASIFICACIÓN SIN REGULARIZACIÓN\n",
    "    print('LOGISTIC REGRESSION WITHOUT REGULARIZATION')\n",
    "    theta_opt = get_opt_thetas(theta, X_train, Y_train, reg=False)\n",
    "    predict_no_reg = predict(theta_opt, X_test, Y_test)\n",
    "    \n",
    "    # CLASIFICACIÓN CON REGULARIZACIÓN\n",
    "    print('LOGISTIC REGRESSION WITH REGULARIZATION')\n",
    "    theta_opt_reg = get_opt_thetas(theta, X_train, Y_train, reg=True)\n",
    "    predict_reg = predict(theta_opt_reg, X_test, Y_test)\n",
    "    \n",
    "    if predict_no_reg > predict_reg:\n",
    "        save_lr_model(theta_opt)\n",
    "    else:\n",
    "        save_lr_model(theta_opt_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cognitive-defensive",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# main_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-estimate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
